{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "from qiskit import ClassicalRegister, QuantumCircuit, QuantumRegister\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap\n",
    "\n",
    "from qiskit.opflow import X, Y, Z, I, CircuitStateFn\n",
    "from qiskit.opflow.state_fns import StateFn\n",
    "from qiskit.opflow.expectations import PauliExpectation, MatrixExpectation\n",
    "from qiskit.opflow.converters import CircuitSampler\n",
    "from qiskit.providers.aer import QasmSimulator\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even(x):\n",
    "    return (x % 2) == 0\n",
    "\n",
    "\n",
    "def generate_pauli(n):\n",
    "    hamiltonians = []\n",
    "\n",
    "    h = 1\n",
    "    for _ in range(n):\n",
    "        h = h^Z\n",
    "    hamiltonians.append(h)\n",
    "\n",
    "    for k in range(n):\n",
    "       \n",
    "        h = 1\n",
    "\n",
    "        if(k != 0):\n",
    "            for _ in range(k):\n",
    "                h = h^X\n",
    "\n",
    "        if even(k+1):\n",
    "            h = h^X\n",
    "        else:\n",
    "            h = h^Y\n",
    "\n",
    "        if (k+1 != n):\n",
    "            for _ in range(k+1, n):\n",
    "                h = h^Z\n",
    "\n",
    "\n",
    "        hamiltonians.append(h)\n",
    "\n",
    "    return hamiltonians\n",
    "\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ag_clustering(dataset, classes, dissimilarity_matrix, linkage=\"complete\", title=\"\"):\n",
    "    clustering = AgglomerativeClustering(affinity='precomputed', n_clusters=np.unique(classes).size,  linkage=linkage).fit(dissimilarity_matrix)\n",
    "\n",
    "    labels = clustering.labels_\n",
    "    cmap = plt.cm.get_cmap(\"Accent\").copy()\n",
    "    cmap.set_under('red')\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(classes, labels)\n",
    "\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    fig.suptitle(title)\n",
    "    fig.set_size_inches(15,6)\n",
    "\n",
    "    axs[0].set_title(\"Contingency Matrix\")\n",
    "    axs[0].matshow(contingency_matrix, cmap='RdPu')\n",
    "    axs[1].set_title(\"Predicted Clusters\")\n",
    "    axs[1].scatter(dataset[:,0], dataset[:,1], c=labels, cmap=cmap)\n",
    "\n",
    "\n",
    "def dbscan_clustering(dataset, classes, dissimilarity_matrix, eps=0.5, min_samples=5, title=\"\"):\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed').fit(dissimilarity_matrix)\n",
    "\n",
    "    labels = clustering.labels_\n",
    "    cmap = plt.cm.get_cmap(\"Accent\").copy()\n",
    "    cmap.set_under('red')\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(classes, labels)\n",
    "\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    fig.suptitle(title)\n",
    "    fig.set_size_inches(15,6)\n",
    "\n",
    "    axs[0].set_title(\"Contingency Matrix\")\n",
    "    axs[0].matshow(contingency_matrix, cmap='RdPu')\n",
    "    axs[1].set_title(\"Predicted Clusters\")\n",
    "    axs[1].scatter(dataset[:,0], dataset[:,1], c=labels, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_distance_approximate(data_1, data_2, encode_map, observables, simulator):\n",
    "\n",
    "    x = CircuitStateFn(encode_map.bind_parameters(data_1))\n",
    "    y = CircuitStateFn(encode_map.bind_parameters(data_2))\n",
    "\n",
    "    em = 0\n",
    "\n",
    "    for h in observables:\n",
    "\n",
    "        measurable_x = StateFn(h, is_measurement=True).compose(x)\n",
    "        measurable_y = StateFn(h, is_measurement=True).compose(y)\n",
    "\n",
    "        expectation_x = PauliExpectation().convert(measurable_x)\n",
    "        expectation_y = PauliExpectation().convert(measurable_y)\n",
    "\n",
    "        sampler_x = CircuitSampler(simulator).convert(expectation_x)\n",
    "        sampler_y = CircuitSampler(simulator).convert(expectation_y)\n",
    "\n",
    "        current_expectation = abs(sampler_x.eval().real - sampler_y.eval().real)\n",
    "\n",
    "        if current_expectation > em:\n",
    "            em = current_expectation\n",
    "\n",
    "    return em\n",
    "\n",
    "def em_distance_exact(data_1, data_2, encode_map, observables):\n",
    "\n",
    "    x = CircuitStateFn(encode_map.bind_parameters(data_1))\n",
    "    y = CircuitStateFn(encode_map.bind_parameters(data_2))\n",
    "\n",
    "    em = 0\n",
    "\n",
    "    for h in observables:\n",
    "\n",
    "        circuit_x = x.adjoint().compose(h).compose(x)\n",
    "        circuit_y = y.adjoint().compose(h).compose(y)\n",
    "\n",
    "        current_expectation = abs(circuit_x.eval().real - circuit_y.eval().real)\n",
    "\n",
    "        if current_expectation > em:\n",
    "            em = current_expectation\n",
    "\n",
    "    return em\n",
    "\n",
    "\n",
    "def em_dissimilarity_matrix(dataset, approximate = False):\n",
    "\n",
    "    encode_map = ZZFeatureMap(feature_dimension=dataset.shape[1], reps=1, entanglement='linear', insert_barriers=True)\n",
    "    n = encode_map.num_qubits\n",
    "    observables = generate_pauli(n)\n",
    "    mat = np.zeros((dataset.shape[0], dataset.shape[0]))\n",
    "\n",
    "    if approximate:\n",
    "        simulator = QasmSimulator()\n",
    "\n",
    "        for i in range(dataset.shape[0]):\n",
    "            for j in range(i):\n",
    "                dis = em_distance_approximate(dataset[i], dataset[j], encode_map, observables, simulator)\n",
    "                mat[i,j] = dis\n",
    "                mat[j,i] = dis\n",
    "    else:\n",
    "\n",
    "        for i in range(dataset.shape[0]):\n",
    "            for j in range(i):\n",
    "                dis = em_distance_exact(dataset[i], dataset[j], encode_map, observables)\n",
    "                mat[i,j] = dis\n",
    "                mat[j,i] = dis\n",
    "\n",
    "    return mat\n",
    "\n",
    "def euclidean_matrix(dataset):\n",
    "    mat = np.zeros((dataset.shape[0], dataset.shape[0]))\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "        for j in range(i):\n",
    "            dis = np.sqrt(np.sum((dataset[i] - dataset[j])**2))\n",
    "            mat[i,j] = dis\n",
    "            mat[j,i] = dis\n",
    "\n",
    "    return mat\n",
    "\n",
    "\n",
    "def manhattan_matrix(dataset):\n",
    "    mat = np.zeros((dataset.shape[0], dataset.shape[0]))\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "        for j in range(i):\n",
    "            dis = np.sum(np.abs(dataset[i] - dataset[j]))\n",
    "            mat[i,j] = dis\n",
    "            mat[j,i] = dis\n",
    "\n",
    "    return mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 20\n",
    "\n",
    "dataset, classes = datasets.make_blobs(n_samples=TRAIN_SIZE, random_state=10, centers=2, n_features=2)\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "plt.scatter(dataset[:,0], dataset[:,1], c=classes, cmap=\"Accent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_diss = em_dissimilarity_matrix(dataset, approximate=False)\n",
    "l2_diss = euclidean_matrix(dataset)\n",
    "l1_diss = manhattan_matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,3)\n",
    "fig.set_size_inches(15,6)\n",
    "\n",
    "axs[0].matshow(em_diss, cmap='RdPu')\n",
    "axs[0].set_title(\"EM Distance\")\n",
    "axs[1].matshow(l1_diss, cmap='RdPu')\n",
    "axs[1].set_title(\"Manhattan Distance\")\n",
    "axs[2].matshow(l2_diss, cmap='RdPu')\n",
    "axs[2].set_title(\"Euclidean Distance\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_clustering(dataset = dataset, classes = classes, dissimilarity_matrix = em_diss, linkage=\"complete\", title = \"EM\")\n",
    "ag_clustering(dataset = dataset, classes = classes, dissimilarity_matrix = l2_diss, linkage=\"complete\", title = \"Euclidean\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_clustering(dataset=dataset, classes=classes, dissimilarity_matrix=em_diss, eps=2, min_samples=10, title=\"EM\")\n",
    "dbscan_clustering(dataset=dataset, classes=classes, dissimilarity_matrix=l2_diss, eps=5, min_samples=20, title=\"Euclidean\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad11a8bee41c5e9e49935bcfc057bf24c040f5e4c134dd6ff301c88f66bc37e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
